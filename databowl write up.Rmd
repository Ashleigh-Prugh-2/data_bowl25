
---
title: "Player and Team Evaluation in the NFL: Targeting and Play Success Prediction"
author: "Ashleigh Prugh"
output: html_document
---

## Paper on the NFL Prediction Models Using XGBoost

### Abstract
This paper presents a framework for predicting various outcomes in National Football League (NFL) games using machine learning models. Specifically, it utilizes XGBoost for pre-snap, post-snap, and play success predictions, with an emphasis on the interaction between offensive and defensive players and their impact on game outcomes. The framework incorporates multiple data transformations, including feature engineering, one-hot encoding, and cross-validation, to evaluate the models. Additionally, we explore the calibration of the predicted probabilities using the "iml" package to ensure the models are providing accurate probabilistic forecasts. The results demonstrate the applicability of machine learning models for NFL analytics, particularly in predicting the likelihood of pass targets and play success.

### Introduction
In the NFL, analyzing player performance and predicting game outcomes has evolved from basic statistics to advanced machine learning techniques. Football is a dynamic game with multiple moving parts, and the interaction between offensive and defensive players at various stages of the play is crucial for determining success. Traditional methods often fail to capture the complexity and nuances of these interactions. This paper seeks to bridge this gap by employing machine learning models, specifically XGBoost, to predict player behavior and overall play success in the NFL.

The primary objectives of this research are:
1. To predict whether a receiver will be targeted before and after the motion phase of a play.
2. To predict the success of a play based on the likelihood of gaining positive expected points.
3. To evaluate the model performance using appropriate metrics such as Root Mean Squared Error (RMSE).
4. To assess model calibration to ensure reliable probabilistic predictions.

The models developed in this paper are trained using a variety of features that describe both player positions and situational game data, and are evaluated using rigorous cross-validation techniques.

### Data and Feature Engineering

#### Data Preparation
The dataset consists of player tracking data from NFL games, containing detailed information about each player's position, speed, and other attributes, as well as game-specific features like down, yards to go, and the score difference. The initial preparation process involves filtering missing values and calculating additional features, such as the relative distance between offensive and defensive players.

```{r}
# Data preparation function to calculate Euclidean distance and filter relevant columns
library(dplyr)       # For data wrangling
library(fastDummies) # For creating dummy variables
library(xgboost)     # For XGBoost modeling
library(iml)         # For interpreting machine learning models
library(caret)       # For cross-validation and evaluation
library(ggplot2)     # For plotting and visualizations
library(arrow)       # For efficient data I/O
library(data.table)  # For memory-efficient data processing
library(Matrix)      # For sparse matrix conversion
library(tidyr)       # For data tidying
library(readr)

prepare_data <- function(mismatch_data) {
  mismatch_data <- mismatch_data %>%
    filter(!is.na(wasTargettedReceiver)) %>%
    mutate(relative_distance = sqrt(x_diff^2 + y_diff^2)) %>%
    fastDummies::dummy_cols(mismatch_data, select_columns = c('offensive_position', 'primary_defensive_position'), remove_selected_columns = TRUE) %>%
    fastDummies::dummy_cols(mismatch_data, select_columns = c('pff_passCoverage'), remove_selected_columns = TRUE) %>%
    mutate(play_success = case_when(
      expectedPointsAdded > 0 ~ 1,
      TRUE ~ 0
    )) %>%
    select(frameId, gameId, playId, nflId, relative_distance, is_motion, speed_diff, distance_from_ball, x_diff, y_diff, down, yardsToGo, score_diff, gameClock_seconds, mismatch, wasTargettedReceiver, height_diff, weight_diff, expectedPointsAdded, yardsGained, motion_frame, ball_snap_frame, play_success, starts_with("offensive_position_"), starts_with("primary_defensive_position_"), starts_with('pff_passCoverage_'))
  return(mismatch_data)
}

# Read and combine all datasets
read_and_combine_datasets <- function(data_dir, weeks) {
  files <- paste0(data_dir, "/prepared_data_week_", weeks, ".parquet")
  combined_data <- bind_rows(lapply(files, read_parquet))
  return(combined_data)
}

# Split data into training and testing sets
split_data <- function(data, train_ratio = 0.8, seed = 42) {
  set.seed(seed)
  train_indices <- sample(1:nrow(data), size = train_ratio * nrow(data))
  train_data <- data[train_indices, ]
  test_data <- data[-train_indices, ]
  return(list(train = train_data, test = test_data))
}
```

The dataset is filtered to remove instances where the target information is missing, and categorical variables (e.g., player positions, coverage schemes) are one-hot encoded. Additionally, the Euclidean distance between the offensive player and the defender is computed to capture the proximity of the players.

#### Feature Selection
Several features are selected based on their relevance to predicting whether a receiver will be targeted, the outcome of the play, and overall play success. These features include:
- **Relative Distance**: The distance between the offensive player and the defender.
- **Speed Differences**: The relative speed difference between the offensive player and the defender.
- **Player Attributes**: Height and weight differences between the players.
- **Game Context**: Information like down, yards to go, and game clock.
- **Position Mismatches**: For example a wide receiver (WR) lines up against a linebacker (LB) in man-to-man coverage..

### Model Development

#### Pre-motion and Post-motion Models
To predict the likelihood of a receiver being targeted, the dataset is divided into two phases: pre-motion (before the receiver starts moving) and post-motion (after the receiver begins motion but before the ball snap). For each phase, separate XGBoost models are trained. The objective is to predict whether a receiver will be targeted in these phases.

```{r}
# Training XGBoost model for pre-motion phase
train_xgboost_model <- function(train_data) {
  train_data <- train_data %>% filter(frameId < motion_frame)  # Filter for pre-motion phase
  x_features_pre_motion <- train_data %>%
    select(relative_distance, is_motion, speed_diff, distance_from_ball, x_diff, y_diff, down, yardsToGo, score_diff, gameClock_seconds, mismatch, height_diff, weight_diff, starts_with("offensive_position_"), starts_with("primary_defensive_position_"), starts_with('pff_passCoverage_'))
  dtrain <- xgb.DMatrix(data = as.matrix(x_features_pre_motion), label = train_data$wasTargettedReceiver)
  params <- list(objective = 'binary:logistic', eval_metric = 'logloss', max_depth = 6, eta = 0.1, subsample = 0.8)
  model <- xgboost(params = params, data = dtrain, nrounds = 100, verbose = 0)
  return(model)
}

# Train post-motion model (XGBoost)
train_post_motion_xgboost <- function(train_data) {
  train_data <- train_data %>% filter(frameId > motion_frame & frameId < ball_snap_frame)  # Filter post-motion but before ball snap
  
  x_features_post_motion <- train_data %>% 
    select(relative_distance, is_motion, speed_diff, max_speed_diff, distance_from_ball, 
           x_diff, y_diff, down, yardsToGo, score_diff, gameClock_seconds, 
           mismatch, height_diff, weight_diff, starts_with("offensive_position_"), starts_with("primary_defensive_position_"), starts_with('pff_passCoverage_'))
  
  dtrain_post_motion <- xgb.DMatrix(data = as.matrix(x_features_post_motion), label = train_data$wasTargettedReceiver)
  
  params_post_motion <- list(objective = 'binary:logistic', eval_metric = 'logloss', max_depth = 6, eta = 0.1, subsample = 0.8)
  model_post_motion <- xgboost(params = params_post_motion, data = dtrain_post_motion, nrounds = 100, verbose = 0)
  
  return(model_post_motion)
}
```

The pre-motion model is trained on features like relative distance, speed difference, and game context (down, yards to go), while the post-motion model is trained on the same set of features but considers frames after the motion begins but before the ball snap.

#### Play Success Model
In addition to predicting receiver targeting, we also build a model to predict the success of the play. This model predicts whether the play will result in a positive expected points added (EPA).

```{r}
# Training play success model
train_play_success_model <- function(train_data) {
  train_data <- train_data %>%
    filter(frameId < ball_snap_frame) %>%
    filter(wasTargettedReceiver == 1) %>%
    mutate(play_success = case_when(expectedPointsAdded > 0 ~ 1, TRUE ~ 0))
  x_features_success <- train_data %>%
    select(relative_distance, is_motion, speed_diff, distance_from_ball, x_diff, y_diff, down, yardsToGo, score_diff, gameClock_seconds, mismatch, height_diff, weight_diff, starts_with("offensive_position_"), starts_with("primary_defensive_position_"), starts_with('pff_passCoverage_'), expectedPointsAdded, yardsGained)
  dtrain_success <- xgb.DMatrix(data = as.matrix(x_features_success), label = train_data$play_success)
  params_success <- list(objective = 'binary:logistic', eval_metric = 'logloss', max_depth = 6, eta = 0.1, subsample = 0.8)
  model_success <- xgboost(params = params_success, data = dtrain_success, nrounds = 100, verbose = 0)
  return(model_success)
}

# Function to predict pre-motion, post-motion, and play success probabilities
predict_play_outcome <- function(model_pre_motion, model_post_motion, model_success, test_data) {
  # Ensure consistent feature preparation
  test_data <- test_data %>%
    mutate(play_success = case_when(
      expectedPointsAdded > 0 ~ 1,
      TRUE ~ 0
    ))
  
  # Pre-motion prediction
  x_features_pre_motion <- test_data %>%
    select(relative_distance, is_motion, speed_diff, max_speed_diff, distance_from_ball,
           x_diff, y_diff, down, yardsToGo, score_diff, gameClock_seconds,
           mismatch, height_diff, weight_diff, starts_with("offensive_position_"), 
           starts_with("primary_defensive_position_"), starts_with('pff_passCoverage_'))
  dtest_pre_motion <- xgb.DMatrix(data = as.matrix(x_features_pre_motion))
  pre_motion_preds <- predict(model_pre_motion, dtest_pre_motion)
  
  # Post-motion prediction
  x_features_post_motion <- x_features_pre_motion
  dtest_post_motion <- xgb.DMatrix(data = as.matrix(x_features_post_motion))
  post_motion_preds <- predict(model_post_motion, dtest_post_motion)
  
  # Success prediction
  x_features_success <- test_data %>%
    select(relative_distance, is_motion, speed_diff, max_speed_diff, distance_from_ball,
           x_diff, y_diff, down, yardsToGo, score_diff, gameClock_seconds,
           mismatch, height_diff, weight_diff, starts_with("offensive_position_"), 
           starts_with("primary_defensive_position_"), starts_with('pff_passCoverage_'), expectedPointsAdded, yardsGained)
  
  dtest_success <- xgb.DMatrix(data = as.matrix(x_features_success))
  success_preds <- predict(model_success, dtest_success)
  
  return(list(pre_motion_preds = pre_motion_preds, post_motion_preds = post_motion_preds, success_preds = success_preds))
}

```

This model is trained on features that influence play success, including the expected points added and yards gained.

### Model Evaluation

#### RMSE Calculation
To evaluate the performance of the models, we use the Root Mean Squared Error (RMSE) metric. This measure provides insight into the accuracy of the models' predictions, comparing the predicted probabilities against actual outcomes.

```{r} 
prepared_data <- read_csv('/Users/user/combined_data.csv') 

# Step 3: Split into training and test sets
splits <- split_data(prepared_data)
train_data <- splits$train
test_data <- splits$test

# Step 4: Train models
model_pre_motion <- train_xgboost_model(train_data)
model_post_motion <- train_post_motion_xgboost(train_data)
model_success <- train_play_success_model(train_data)

# Step 5: Evaluate models on test data
test_predictions <- predict_play_outcome(model_pre_motion, model_post_motion, model_success, test_data)

# Function to calculate RMSE
calculate_rmse <- function(actual, predicted) {
  sqrt(mean((actual - predicted)^2))
}

# Calculate RMSE for evaluation
rmse_pre_motion <- calculate_rmse(test_data$wasTargettedReceiver, test_predictions$pre_motion_preds)
rmse_post_motion <- calculate_rmse(test_data$wasTargettedReceiver, test_predictions$post_motion_preds)
rmse_play_success <- calculate_rmse(test_data$play_success, test_predictions$success_preds)

# Print RMSE results
rmse_results <- data.frame(
  Model = c("Pre-Motion", "Post-Motion", "Play Success"),
  RMSE = c(rmse_pre_motion, rmse_post_motion, rmse_play_success)
)
print(rmse_results)


```

#### Calibration Plot
One of the challenges in predicting NFL outcomes is ensuring that the probabilities output by the model are well-calibrated. Using the "iml" package, we can plot the calibration curves to assess how well the predicted probabilities match the observed frequencies.

```{r}
# Calibration plot
library(iml)
predictor <- Predictor$new(model = model_success, data = test_data, y = test_data$play_success)
calibration <- Calibration$new(predictor)
calibration$plot()
```

This plot allows analysts to visually inspect whether the predicted probabilities of play success align with the actual success rates.

### Results and Discussion

#### Model Performance
After training and evaluating the models, we report the RMSE values for the pre-motion, post-motion, and play success models. These values provide an indication of the model's ability to predict targeted receivers and play outcomes with high accuracy.

```{r}
cat("RMSE for pre-snap model:", rmse_pre_motion, "\n")
cat("RMSE for post-snap model:", rmse_post_motion, "\n")
cat("RMSE for play success model:", rmse_success, "\n")
```

#### Model Viz 

```{r} 
# Load necessary libraries
library(dplyr)
library(arrow)
library(ggplot2)
library(gganimate)
library(xgboost)
library(fastDummies)
library(data.table)

# Assuming the models are already trained (from previous code)

# 1. Filter for a Specific Play (e.g., gameId = 2021090900, playId = 75)
game_id <- 2022091200  # Example gameId
play_id <- 346          # Example playId

tracking <- fread("/Users/user/Desktop/data bowl 2025/tracking_week_1.csv") #, select = c("gameId", "playId", "nflId", "x", "y", "s", "dis", "o", "dir", "event", "position"))


# Filter the dataset to the specific play
play_data <- prepared_data %>%  
  filter(gameId == game_id, playId == play_id)

tracking <- tracking %>%  
  select(gameId, playId, frameId, nflId, x, y, s, a, o, dir) %>%  
  filter(gameId == game_id, playId == play_id)

library(dplyr)

players <- read.csv('/Users/user/Desktop/data bowl 2025/players.csv')


# Join for offensive nflId
play_data_offense <- play_data %>% 
  filter(!is.na(off_nflId)) %>% 
  rename(nflId = off_nflId) 


play_data <- left_join(tracking, play_data_offense, by= c('gameId', 'playId', 'frameId', 'nflId'))

play_data <- left_join(play_data, players, by = c('nflId'))




# 2. Prepare the data for prediction
# Pre-motion predictions
x_features_pre_motion <- play_data %>%  
  select(relative_distance, is_motion, speed_diff, max_speed_diff, distance_from_ball,
         x_diff, y_diff, down, yardsToGo, score_diff, gameClock_seconds,
         mismatch, height_diff, weight_diff, starts_with("offensive_position_"),  
         starts_with("primary_defensive_position_"), starts_with('pff_passCoverage_'))
dtest_pre_motion <- xgb.DMatrix(data = as.matrix(x_features_pre_motion))
pre_motion_preds <- predict(model_pre_motion, dtest_pre_motion)

# Post-motion predictions
x_features_post_motion <- x_features_pre_motion
dtest_post_motion <- xgb.DMatrix(data = as.matrix(x_features_post_motion))
post_motion_preds <- predict(model_post_motion, dtest_post_motion)

# Success predictions
x_features_success <- play_data %>%
  select(relative_distance, is_motion, speed_diff, max_speed_diff, distance_from_ball,
         x_diff, y_diff, down, yardsToGo, score_diff, gameClock_seconds,
         mismatch, height_diff, weight_diff, starts_with("offensive_position_"),  
         starts_with("primary_defensive_position_"), starts_with('pff_passCoverage_'), expectedPointsAdded, yardsGained)
dtest_success <- xgb.DMatrix(data = as.matrix(x_features_success))
success_preds <- predict(model_success, dtest_success)

# Add the predictions (probabilities) to the play data
play_data <- play_data %>%
  mutate(pre_motion_prob = pre_motion_preds,
         post_motion_prob = post_motion_preds,
         play_success_prob = success_preds) 

play_data <- left_join(play_data, players, by = c('nflId'))

# 3. Create the Football Field Plot for Animation
create_field <- function() {
  ggplot() +
    geom_rect(aes(xmin = 0, xmax = 120, ymin = 0, ymax = 53.3), fill = "#006400") +
    geom_vline(xintercept = seq(10, 110, by = 10), color = "white", linetype = "dashed") +
    geom_hline(yintercept = c(0, 53.3), color = "white") +
    theme_minimal() +
    theme(
      panel.grid = element_blank(),
      axis.text = element_blank(),
      axis.title = element_blank(),
      axis.ticks = element_blank()
    )
}

animation <- create_field() + 
  # Players: Color them by pre-motion probability, but grey out those with NA in offensive_position_ columns
  geom_point(data = play_data %>% filter(!is.na(nflId)), aes(x = x, y = y, color = pre_motion_prob), size = 3) + 
  geom_point(data = play_data %>%
               mutate(
                 all_na_or_zero_in_positions = rowSums(
                   !is.na(select(., starts_with("offensive_position_"))) & 
                     select(., starts_with("offensive_position_")) != 0
                 ) == 0  # Check if all values are either NA or 0
               ) %>%
               filter(all_na_or_zero_in_positions),
             aes(x = x, y = y), color = "grey", size = 3) + 
  geom_text(data = play_data %>% 
              filter(!is.na(nflId), pre_motion_prob > 0.16),  # Add filter for pre_motion_prob > 0
            aes(x = x, y = y, label = sprintf("%.2f", pre_motion_prob)), 
            color = "white", size = 3, vjust = -1) +  # Display probability as text for players
  geom_text(data = play_data %>% 
              filter(!is.na(nflId), pre_motion_prob > 0.16),  # Add filter for pre_motion_prob > 0
            aes(x = x, y = y, label = displayName), 
            color = "black", size = 3, vjust = 1.5) +  # Add player names below the points
  # Ball: Rows with NA in nflId correspond to the ball
  geom_point(data = play_data %>% filter(is.na(nflId)), aes(x = x, y = y), color = "orange", size = 3, shape = 16) + 
  scale_color_gradient(low = "blue", high = "red") + 
  labs(title = paste("Play Animation | Game: ", game_id, " | Play: ", play_id, " | Frame: {frameId}"),
       subtitle = "Pre-Motion Target Probability", 
       color = "Target Probability") + 
  transition_states(frameId, transition_length = 1, state_length = 1) + 
  ease_aes('linear')


# Save the Animation as a GIF
animate(animation, width = 800, height = 400, fps = 10, renderer = gifski_renderer("play_animation_with_names.gif"))

# Optionally display the animation in the console
animate(animation, width = 800, height = 400, fps = 10)



```

### Adding Team and Player Evaluations to NFL Prediction Models

Building upon the previous work that involves predicting receiver targeting and play success, we can extend the models to evaluate individual players and teams. Player and team evaluations are critical in NFL analytics for assessing player performance, strategy effectiveness, and identifying strengths and weaknesses during a game. Using the model outputs, we can generate performance metrics for individual players and teams, which can provide actionable insights for coaches, analysts, and teams themselves.

In this section, we describe how to leverage the pre-motion, post-motion, and play success models to evaluate players and teams using a structured workflow. We also provide the necessary R code to implement these evaluations based on the outputs of the aforementioned models.

---

### 1. **Player Evaluation**

```{r} 
# Top-performing players by mismatch
top_players <- prepared_data %>%
  group_by(off_nflId) %>% 
  summarise(
    total_success = mean(play_success, na.rm = TRUE),
    avg_epa = mean(expectedPointsAdded, na.rm = TRUE),
    mismatch_count = n()
  ) %>%
  arrange(desc(total_success))

top_players <- left_join(top_players, players, by = c('off_nflId' = 'nflId')) 

top_players_te <- top_players %>% 
  filter(position == 'TE')

top_players_wr <- top_players %>% 
filter(position == 'WR')

print(top_players) 

```

```{r} 
# Calculate pre-snap motion usage and target probability by team
calculate_motion_effectiveness <- function(data, pre_motion_preds) {
  data <- data %>%
    mutate(pre_snap_motion_used = ifelse(is_motion == 1, 1, 0)) %>%
    group_by(possessionTeam) %>%
    summarise(
      total_plays = n(),
      motion_plays = sum(pre_snap_motion_used),
      motion_target_rate = mean(pre_motion_preds[pre_snap_motion_used == 1]),
      motion_usage_rate = mean(pre_snap_motion_used)
    )
  
  data <- data %>%
    mutate(motion_effectiveness = motion_target_rate * motion_usage_rate) # Define effectiveness as motion target rate weighted by usage rate
  
  return(data)
}

plays <- read.csv('/Users/user/Desktop/data bowl 2025/plays.csv')


test_data <- left_join(test_data, plays, by = c('gameId', 'playId'))

# Apply this function to the dataset
motion_effectiveness <- calculate_motion_effectiveness(test_data, test_predictions$pre_motion_preds)

# Sort teams by motion effectiveness
motion_effectiveness_sorted <- motion_effectiveness %>%
  arrange(desc(motion_effectiveness))

# Display top teams with highest motion effectiveness
head(motion_effectiveness_sorted)


```

---

### 3. **Putting It All Together**

Using the above evaluation functions, we can create a comprehensive performance report for both individual players and teams. The workflow is as follows:

1. **Prepare Data**: Clean and preprocess the data (as described in the original workflow).
2. **Train Models**: Train the pre-motion, post-motion, and play success models.
3. **Evaluate Player Performance**: Use the targeting and play success models to compute player-level evaluation metrics (targeting score and play success score).
4. **Evaluate Team Performance**: Aggregate player-level evaluations to compute team-level metrics (team targeting and team play success).

```{r}
# Assuming 'test_data' and 'player_data' are available (player-level information like team abbreviation, player IDs)
player_targeting <- evaluate_player_targeting(test_data, model_pre_motion, model_post_motion)
player_success <- evaluate_player_play_success(test_data, model_success)

# Aggregating player-level metrics for team evaluation
team_targeting <- evaluate_team_targeting(player_targeting, player_data)
team_play_success <- evaluate_team_play_success(player_success, player_data)

# Output the results
print("Player Targeting Scores:")
print(player_targeting)

print("Player Play Success Scores:")
print(player_success)

print("Team Targeting Scores:")
print(team_targeting)

print("Team Play Success Scores:")
print(team_play_success)
```

### Conclusion

By extending the machine learning models to include player and team evaluations, we provide a comprehensive framework for NFL performance analytics. This approach not only allows for individual player performance assessments but also aggregates those metrics to evaluate team strategies and overall effectiveness. 

The combination of pre-motion, post-motion, and play success predictions offers a dynamic view of a player's and team's likelihood of success at various stages of a play. This framework can be adapted to different stages of a game, different positions, and various other football analytics tasks, providing a robust toolset for NFL analysts, coaches, and decision-makers.

Future improvements could include incorporating more complex features, such as player fatigue, defensive schemes, and real-time game situations, to further enhance the accuracy of the models and evaluations.
